{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.bedrock_agent import Agent, SupervisorAgent, Task, region, account_id, agents_helper\n",
    "from textwrap import dedent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import zipfile\n",
    "import subprocess\n",
    "\n",
    "sts_client = boto3.client('sts')\n",
    "session = boto3.session.Session()\n",
    "\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "region = session.region_name\n",
    "account_id_suffix = account_id[:3]\n",
    "agent_suffix = f\"{region}-{account_id_suffix}\"\n",
    "\n",
    "s3_client = boto3.client('s3', region)\n",
    "bedrock_client = boto3.client('bedrock-runtime', region)\n",
    "iam_client = boto3.client('iam', region)\n",
    "lambda_client = boto3.client('lambda', region)\n",
    "\n",
    "\n",
    "# 'anthropic.claude-3-5-sonnet-20240620-v1:0',\n",
    "# 'anthropic.claude-3-sonnet-20240229-v1:0',\n",
    "# 'anthropic.claude-3-haiku-20240307-v1:0'\n",
    "\n",
    "agent_foundation_model = [\n",
    "    'anthropic.claude-3-5-sonnet-20241022-v2:0'\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Agent.set_force_recreate_default(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Schemas formatted for OSS Index\n",
    "with open('schemas/ecom_shipping_schema.json', 'r') as file:\n",
    "    ecom_shipping_schema = json.load(file)\n",
    "\n",
    "ecom_shipping_schema_string= json.dumps(ecom_shipping_schema, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting existing agent and corresponding lambda for: dsl-query-agent-us-west-2-533...\n",
      "Found target agent, name: dsl-query-agent-us-west-2-533, id: WJYFKTH1IX\n",
      "Deleting aliases for agent WJYFKTH1IX...\n",
      "Deleting alias 55BQIJMVGI from agent WJYFKTH1IX\n",
      "Deleting alias TSTALIASID from agent WJYFKTH1IX\n",
      "Deleting agent: WJYFKTH1IX...\n",
      "Deleting IAM role: AmazonBedrockExecutionRoleForAgents_dsl-query-agent-us-west-2-533...\n",
      "Creating agent dsl-query-agent-us-west-2-533...\n",
      "Created agent, id: AK3UI7V9RL, alias id: TSTALIASID\n",
      "\n",
      "Adding action group with Lambda: arn:aws:lambda:us-west-2:533267284022:function:execute-dsl-query-us-west-2-533...\n",
      "Waiting for agent status to change. Current status CREATING\n",
      "Agent id AK3UI7V9RL current status: NOT_PREPARED\n",
      "Waiting for agent status to change. Current status VERSIONING\n",
      "Agent id AK3UI7V9RL current status: PREPARED\n",
      "DONE: Agent: dsl-query-agent-us-west-2-533, id: AK3UI7V9RL, alias id: BDZDCS2YJE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dsl_query_agent = Agent.direct_create(\n",
    "    name=f\"dsl-query-agent-{agent_suffix}\",\n",
    "    role=\"DSL Query Creator\",\n",
    "    goal=\"Create DSL queries for a given user query\",\n",
    "    instructions=f\"\"\"\n",
    "    You are an expert in generating Query DSL for Elasticsearch-style queries. Your task is to convert a given natural language user question into a well-structured Query DSL.\n",
    "    \n",
    "    ## Instructions:\n",
    "    - Use the provided e-commerce shipping schema to construct the query.\n",
    "    - Encapsulate the output in <json>...</json> tags.\n",
    "    - Follow the syntax of the Query DSL strictly; do not introduce elements outside the provided schema.\n",
    "    \n",
    "    ## Query Construction Rules:\n",
    "    - **Keyword fields** (e.g., carrier, status, country): Use `term` for exact matches or `prefix`/`wildcard` for partial matches.\n",
    "    - **Text fields** (e.g., description, address): Use `match` queries to account for analyzed terms.\n",
    "    - **Nested fields** (e.g., tracking): Always use `nested` queries.\n",
    "    - **Date fields**: Use `range` queries with date math for filtering by date ranges.\n",
    "    - Break down complex queries into smaller parts for accuracy.\n",
    "    - Think step-by-step before constructing the query.\n",
    "\n",
    "    ## Schema:\n",
    "    {ecom_shipping_schema_string}\n",
    "\n",
    "    ## Output Format:\n",
    "    - Return only the generated Query DSL within <json>...</json> tags.\n",
    "    - Do not include explanations, comments, or additional text.\n",
    "    \"\"\",\n",
    "    tool_code=f\"arn:aws:lambda:{region}:{account_id}:function:execute-dsl-query-us-west-2-533\",\n",
    "    tool_defs=[\n",
    "        {\n",
    "            \"name\": \"execute_dsl_query\",\n",
    "            \"description\": \"Executes a given DSL query and returns the results\",\n",
    "            \"parameters\": {\n",
    "                \"dsl_query\": {\n",
    "                    \"description\": \"The DSL query to execute\",\n",
    "                    \"type\": \"string\",\n",
    "                    \"required\": True,\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent ID for DSL Query Agent: AK3UI7V9RL\n",
      "Agent ID for Query Fixer Agent: QXAMFSD0AH\n"
     ]
    }
   ],
   "source": [
    "dsl_query_agent_id = agents_helper.get_agent_id_by_name(f\"dsl-query-agent-{agent_suffix}\")\n",
    "print(f\"Agent ID for DSL Query Agent: {dsl_query_agent_id}\")\n",
    "\n",
    "query_fixer_agent_id = agents_helper.get_agent_id_by_name(f\"query-fixer-agent-{agent_suffix}\")\n",
    "print(f\"Agent ID for Query Fixer Agent: {query_fixer_agent_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_iam_role(role_name):\n",
    "    \"\"\"Creates an IAM Role with necessary trust policy for Lambda.\"\"\"\n",
    "    \n",
    "    assume_role_policy_document = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Principal\": {\n",
    "                    \"Service\": \"lambda.amazonaws.com\"\n",
    "                },\n",
    "                \"Action\": \"sts:AssumeRole\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        role = iam_client.create_role(\n",
    "            RoleName=role_name,\n",
    "            AssumeRolePolicyDocument=json.dumps(assume_role_policy_document)\n",
    "        )\n",
    "        print(f\"IAM Role {role_name} created.\")\n",
    "    except iam_client.exceptions.EntityAlreadyExistsException:\n",
    "        print(f\"IAM Role {role_name} already exists.\")\n",
    "        role = iam_client.get_role(RoleName=role_name)\n",
    "\n",
    "    # Attach AWS Lambda execution policy\n",
    "    iam_client.attach_role_policy(\n",
    "        RoleName=role_name,\n",
    "        PolicyArn=\"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # Attach additional policies for OpenSearch access\n",
    "    opensearch_policy_document = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Action\": [\n",
    "                    \"es:Describe*\",\n",
    "                    \"es:List*\",\n",
    "                    \"es:Get*\"\n",
    "                ],\n",
    "                \"Resource\": \"*\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    opensearch_policy_name = f\"{role_name}-OpenSearchPolicy\"\n",
    "    try:\n",
    "        iam_client.put_role_policy(\n",
    "            RoleName=role_name,\n",
    "            PolicyName=opensearch_policy_name,\n",
    "            PolicyDocument=json.dumps(opensearch_policy_document)\n",
    "        )\n",
    "        print(f\"Attached OpenSearch policy to IAM Role {role_name}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to attach OpenSearch policy to IAM Role {role_name}: {e}\")\n",
    "\n",
    "\n",
    "    # Attach the new policy for aoss:APICall\n",
    "    aoss_policy_document = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Action\": [\n",
    "                    \"aoss:*\"\n",
    "                ],\n",
    "                \"Resource\": \"*\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    aoss_policy_name = f\"{role_name}-AOSSPolicy\"\n",
    "    try:\n",
    "        iam_client.put_role_policy(\n",
    "            RoleName=role_name,\n",
    "            PolicyName=aoss_policy_name,\n",
    "            PolicyDocument=json.dumps(aoss_policy_document)\n",
    "        )\n",
    "        print(f\"Attached AOSS policy to IAM Role {role_name}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to attach AOSS policy to IAM Role {role_name}: {e}\")\n",
    "\n",
    "\n",
    "    role_arn = role['Role']['Arn']\n",
    "\n",
    "    # Wait for IAM role to propagate\n",
    "    print(\"Waiting for IAM role to be usable...\")\n",
    "    time.sleep(10)  # Delay to allow propagation\n",
    "\n",
    "    return role_arn\n",
    "\n",
    "\n",
    "def create_zip_file(source_file, zip_file_path):\n",
    "    with zipfile.ZipFile(zip_file_path, 'w') as zipf:\n",
    "        zipf.write(source_file, os.path.basename(source_file))\n",
    "\n",
    "def create_lambda_package(source_file, zip_file_path):\n",
    "    \"\"\"Packages the Lambda function and its dependencies into a ZIP file.\"\"\"\n",
    "    package_dir = \"package\"\n",
    "    \n",
    "    # Install dependencies\n",
    "    if not os.path.exists(package_dir):\n",
    "        os.makedirs(package_dir)\n",
    "    print(\"Installing dependencies...\")\n",
    "    subprocess.run(f\"pip install {' '.join(DEPENDENCIES)} -t {package_dir}\", shell=True, check=True)\n",
    "\n",
    "    # Create ZIP file with dependencies and function\n",
    "    print(\"Creating Lambda deployment package...\")\n",
    "    with zipfile.ZipFile(zip_file_path, 'w') as zipf:\n",
    "        for root, _, files in os.walk(package_dir):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                zipf.write(file_path, os.path.relpath(file_path, package_dir))\n",
    "\n",
    "        zipf.write(source_file, os.path.basename(source_file))\n",
    "\n",
    "    # Cleanup temporary package directory\n",
    "    subprocess.run(f\"rm -rf {package_dir}\", shell=True)\n",
    "    print(\"Lambda package created successfully.\")\n",
    "\n",
    "\n",
    "def create_lambda_function(function_name, role_arn, handler, runtime, zip_file_path, region_name=region):\n",
    "    # Initialize a session using Amazon Lambda\n",
    "    lambda_client = boto3.client('lambda', region_name=region_name)\n",
    "\n",
    "    # Read the zip file content\n",
    "    with open(zip_file_path, 'rb') as f:\n",
    "        zip_content = f.read()\n",
    "\n",
    "    # Create the Lambda function\n",
    "    try:\n",
    "        response = lambda_client.create_function(\n",
    "            FunctionName=function_name,\n",
    "            Runtime=runtime,\n",
    "            Role=role_arn,\n",
    "            Handler=handler,\n",
    "            Code={'ZipFile': zip_content},\n",
    "            Description='Lambda function to execute DSL queries',\n",
    "            Timeout=15,\n",
    "            MemorySize=128,\n",
    "            Publish=True\n",
    "        )\n",
    "        print(f\"Lambda function {function_name} created successfully.\")\n",
    "    except lambda_client.exceptions.ResourceConflictException:\n",
    "        print(f\"Lambda function {function_name} already exists. Updating the function...\")\n",
    "\n",
    "        response = lambda_client.update_function_code(\n",
    "            FunctionName=function_name,\n",
    "            ZipFile=zip_content\n",
    "        )\n",
    "        print(f\"Lambda function {function_name} updated successfully.\")\n",
    "\n",
    "    return response\n",
    "\n",
    "def add_resource_based_policy(function_name, agent_ids, region, account_id):\n",
    "    statement_id = \"AllowExecutionFromBedrockAgent\"\n",
    "    policy = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": []\n",
    "    }\n",
    "\n",
    "    for agent_id in agent_ids:\n",
    "        policy['Statement'].append({\n",
    "            \"Sid\": f\"{statement_id}_{agent_id}\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"bedrock.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": \"lambda:InvokeFunction\",\n",
    "            \"Resource\": f\"arn:aws:lambda:{region}:{account_id}:function:{function_name}\",\n",
    "            \"Condition\": {\n",
    "                \"ArnLike\": {\n",
    "                    \"AWS:SourceArn\": f\"arn:aws:bedrock:{region}:{account_id}:agent/{agent_id}\"\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # Check if the statement ID already exists and remove it if necessary\n",
    "    try:\n",
    "        existing_policy = lambda_client.get_policy(FunctionName=function_name)\n",
    "        policy_document = json.loads(existing_policy['Policy'])\n",
    "        for statement in policy_document['Statement']:\n",
    "            if statement['Sid'].startswith(statement_id):\n",
    "                lambda_client.remove_permission(\n",
    "                    FunctionName=function_name,\n",
    "                    StatementId=statement['Sid']\n",
    "                )\n",
    "                print(f\"Removed existing statement ID {statement['Sid']} from Lambda function {function_name}.\")\n",
    "    except lambda_client.exceptions.ResourceNotFoundException:\n",
    "        print(f\"No existing policy found for Lambda function {function_name}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking existing policy for Lambda function {function_name}: {e}\")\n",
    "\n",
    "    # Add the new permissions\n",
    "    try:\n",
    "        for statement in policy['Statement']:\n",
    "            response = lambda_client.add_permission(\n",
    "                FunctionName=function_name,\n",
    "                StatementId=statement['Sid'],\n",
    "                Action=statement['Action'],\n",
    "                Principal=statement['Principal']['Service'],\n",
    "                SourceArn=statement['Condition']['ArnLike']['AWS:SourceArn']\n",
    "            )\n",
    "        print(f\"Resource-based policies added to Lambda function {function_name}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to add resource-based policies to Lambda function {function_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IAM Role LambdaExecutionRole-us-west-2-533 already exists.\n",
      "Attached OpenSearch policy to IAM Role LambdaExecutionRole-us-west-2-533.\n",
      "Attached AOSS policy to IAM Role LambdaExecutionRole-us-west-2-533.\n",
      "Waiting for IAM role to be usable...\n",
      "Installing dependencies...\n",
      "Collecting opensearch-py\n",
      "  Using cached opensearch_py-2.8.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting urllib3\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting python-dateutil (from opensearch-py)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting certifi>=2024.07.04 (from opensearch-py)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting Events (from opensearch-py)\n",
      "  Using cached Events-0.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Using cached charset_normalizer-3.4.1-cp312-cp312-macosx_10_13_universal2.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting six>=1.5 (from python-dateutil->opensearch-py)\n",
      "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Using cached opensearch_py-2.8.0-py3-none-any.whl (353 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp312-cp312-macosx_10_13_universal2.whl (196 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached Events-0.5-py3-none-any.whl (6.8 kB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: Events, urllib3, six, idna, charset-normalizer, certifi, requests, python-dateutil, opensearch-py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.16.1 requires botocore<1.35.89,>=1.35.74, but you have botocore 1.36.9 which is incompatible.\n",
      "datasets 2.21.0 requires dill<0.3.9,>=0.3.0, but you have dill 0.3.9 which is incompatible.\n",
      "datasets 2.21.0 requires fsspec[http]<=2024.6.1,>=2023.1.0, but you have fsspec 2024.12.0 which is incompatible.\n",
      "awscli 1.34.8 requires botocore==1.35.8, but you have botocore 1.36.9 which is incompatible.\n",
      "awscli 1.34.8 requires s3transfer<0.11.0,>=0.10.0, but you have s3transfer 0.11.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed Events-0.5 certifi-2025.1.31 charset-normalizer-3.4.1 idna-3.10 opensearch-py-2.8.0 python-dateutil-2.9.0.post0 requests-2.32.3 six-1.17.0 urllib3-2.3.0\n",
      "Creating Lambda deployment package...\n",
      "Lambda package created successfully.\n",
      "Lambda function execute-dsl-query-us-west-2-533 already exists. Updating the function...\n",
      "Lambda function execute-dsl-query-us-west-2-533 updated successfully.\n",
      "Removed existing statement ID AllowExecutionFromBedrockAgent_AK3UI7V9RL from Lambda function execute-dsl-query-us-west-2-533.\n",
      "Removed existing statement ID AllowExecutionFromBedrockAgent_3T9YA9W3WR from Lambda function execute-dsl-query-us-west-2-533.\n",
      "Resource-based policies added to Lambda function execute-dsl-query-us-west-2-533.\n",
      "{'ResponseMetadata': {'RequestId': 'c23f75ef-9a82-46dd-a57e-8b12508e44a1', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sun, 02 Feb 2025 08:13:29 GMT', 'content-type': 'application/json', 'content-length': '1449', 'connection': 'keep-alive', 'x-amzn-requestid': 'c23f75ef-9a82-46dd-a57e-8b12508e44a1'}, 'RetryAttempts': 0}, 'FunctionName': 'execute-dsl-query-us-west-2-533', 'FunctionArn': 'arn:aws:lambda:us-west-2:533267284022:function:execute-dsl-query-us-west-2-533', 'Runtime': 'python3.12', 'Role': 'arn:aws:iam::533267284022:role/LambdaExecutionRole-us-west-2-533', 'Handler': 'execute_dsl_query.lambda_handler', 'CodeSize': 8105773, 'Description': 'Lambda function to execute DSL queries', 'Timeout': 15, 'MemorySize': 128, 'LastModified': '2025-02-02T08:13:29.000+0000', 'CodeSha256': 'HKdv1m/9JVjT/euQsCcSC4DNA/vnJCKT8UoF7j8vR9Y=', 'Version': '$LATEST', 'TracingConfig': {'Mode': 'PassThrough'}, 'RevisionId': '614ab8fb-5a15-4af2-b048-4d429546ff61', 'State': 'Active', 'LastUpdateStatus': 'InProgress', 'LastUpdateStatusReason': 'The function is being created.', 'LastUpdateStatusReasonCode': 'Creating', 'PackageType': 'Zip', 'Architectures': ['x86_64'], 'EphemeralStorage': {'Size': 512}, 'SnapStart': {'ApplyOn': 'None', 'OptimizationStatus': 'Off'}, 'RuntimeVersionConfig': {'RuntimeVersionArn': 'arn:aws:lambda:us-west-2::runtime:7515e00d6763496e7a147ffa395ef5b0f0c1ffd6064130abb5ecde5a6d630e86'}, 'LoggingConfig': {'LogFormat': 'Text', 'LogGroup': '/aws/lambda/execute-dsl-query-us-west-2-533'}}\n"
     ]
    }
   ],
   "source": [
    "# Define function and role names\n",
    "LAMBDA_FUNCTION_NAME = f\"execute-dsl-query-{agent_suffix}\"\n",
    "IAM_ROLE_NAME = f\"LambdaExecutionRole-{agent_suffix}\"\n",
    "ZIP_FILE_NAME = \"function.zip\"\n",
    "LAMBDA_FILE_PATH = \"src/lambda/execute_dsl_query.py\"\n",
    "DEPENDENCIES = [\"opensearch-py\", \"requests\", \"urllib3\"]  # Required packages\n",
    "\n",
    "\n",
    "# Step 1: Create IAM Role for Lambda\n",
    "role_arn = create_iam_role(IAM_ROLE_NAME)\n",
    "\n",
    "# Step 2: Zip the existing lambda function file\n",
    "if not os.path.exists(LAMBDA_FILE_PATH):\n",
    "    print(f\"Error: {LAMBDA_FILE_PATH} does not exist. Create the file first.\")\n",
    "    exit(1)\n",
    "\n",
    "# Step 3: Package Lambda function and dependencies\n",
    "create_lambda_package(LAMBDA_FILE_PATH, ZIP_FILE_NAME)\n",
    "\n",
    "# Step 4: Create or update the Lambda function\n",
    "response = create_lambda_function(\n",
    "    function_name=LAMBDA_FUNCTION_NAME,\n",
    "    role_arn=role_arn,\n",
    "    handler=\"execute_dsl_query.lambda_handler\",\n",
    "    runtime=\"python3.12\",\n",
    "    zip_file_path=ZIP_FILE_NAME\n",
    ")\n",
    "\n",
    "# Step 4: Add resource-based policy to the Lambda function\n",
    "add_resource_based_policy(LAMBDA_FUNCTION_NAME, [dsl_query_agent_id,query_fixer_agent_id], region, account_id)\n",
    "\n",
    "# add_resource_based_policy(LAMBDA_FUNCTION_NAME, query_fixer_agent_id, region, account_id)\n",
    "\n",
    "\n",
    "# Cleanup: Remove temporary ZIP file\n",
    "os.remove(ZIP_FILE_NAME)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing dependencies...\n",
      "Collecting opensearch-py\n",
      "  Using cached opensearch_py-2.8.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting urllib3\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting python-dateutil (from opensearch-py)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting certifi>=2024.07.04 (from opensearch-py)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting Events (from opensearch-py)\n",
      "  Using cached Events-0.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Using cached charset_normalizer-3.4.1-cp312-cp312-macosx_10_13_universal2.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting six>=1.5 (from python-dateutil->opensearch-py)\n",
      "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Using cached opensearch_py-2.8.0-py3-none-any.whl (353 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp312-cp312-macosx_10_13_universal2.whl (196 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached Events-0.5-py3-none-any.whl (6.8 kB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: Events, urllib3, six, idna, charset-normalizer, certifi, requests, python-dateutil, opensearch-py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.16.1 requires botocore<1.35.89,>=1.35.74, but you have botocore 1.36.9 which is incompatible.\n",
      "datasets 2.21.0 requires dill<0.3.9,>=0.3.0, but you have dill 0.3.9 which is incompatible.\n",
      "datasets 2.21.0 requires fsspec[http]<=2024.6.1,>=2023.1.0, but you have fsspec 2024.12.0 which is incompatible.\n",
      "awscli 1.34.8 requires botocore==1.35.8, but you have botocore 1.36.9 which is incompatible.\n",
      "awscli 1.34.8 requires s3transfer<0.11.0,>=0.10.0, but you have s3transfer 0.11.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed Events-0.5 certifi-2025.1.31 charset-normalizer-3.4.1 idna-3.10 opensearch-py-2.8.0 python-dateutil-2.9.0.post0 requests-2.32.3 six-1.17.0 urllib3-2.3.0\n",
      "Creating Lambda deployment package...\n",
      "Lambda package created successfully.\n",
      "Lambda function execute-modified-dsl-query-us-west-2-533 already exists. Updating the function...\n",
      "Lambda function execute-modified-dsl-query-us-west-2-533 updated successfully.\n",
      "Removed existing statement ID AllowExecutionFromBedrockAgent_AK3UI7V9RL from Lambda function execute-modified-dsl-query-us-west-2-533.\n",
      "Removed existing statement ID AllowExecutionFromBedrockAgent_QXAMFSD0AH from Lambda function execute-modified-dsl-query-us-west-2-533.\n",
      "Resource-based policies added to Lambda function execute-modified-dsl-query-us-west-2-533.\n",
      "{'ResponseMetadata': {'RequestId': '51432a30-bac8-4ba1-a44b-2a9751b69dce', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sun, 02 Feb 2025 08:14:29 GMT', 'content-type': 'application/json', 'content-length': '1476', 'connection': 'keep-alive', 'x-amzn-requestid': '51432a30-bac8-4ba1-a44b-2a9751b69dce'}, 'RetryAttempts': 0}, 'FunctionName': 'execute-modified-dsl-query-us-west-2-533', 'FunctionArn': 'arn:aws:lambda:us-west-2:533267284022:function:execute-modified-dsl-query-us-west-2-533', 'Runtime': 'python3.12', 'Role': 'arn:aws:iam::533267284022:role/LambdaExecutionRole-us-west-2-533', 'Handler': 'execute_dsl_query.lambda_handler', 'CodeSize': 8106021, 'Description': 'Lambda function to execute DSL queries', 'Timeout': 15, 'MemorySize': 128, 'LastModified': '2025-02-02T08:14:29.000+0000', 'CodeSha256': '0CLEoOLYWYQb5WL43flgSUO++/VxEvwEkJS/7hHN9cE=', 'Version': '$LATEST', 'TracingConfig': {'Mode': 'PassThrough'}, 'RevisionId': '93e1e8ea-2bc7-4368-a4ff-f42ca539bb8e', 'State': 'Active', 'LastUpdateStatus': 'InProgress', 'LastUpdateStatusReason': 'The function is being created.', 'LastUpdateStatusReasonCode': 'Creating', 'PackageType': 'Zip', 'Architectures': ['x86_64'], 'EphemeralStorage': {'Size': 512}, 'SnapStart': {'ApplyOn': 'None', 'OptimizationStatus': 'Off'}, 'RuntimeVersionConfig': {'RuntimeVersionArn': 'arn:aws:lambda:us-west-2::runtime:7515e00d6763496e7a147ffa395ef5b0f0c1ffd6064130abb5ecde5a6d630e86'}, 'LoggingConfig': {'LogFormat': 'Text', 'LogGroup': '/aws/lambda/execute-modified-dsl-query-us-west-2-533'}}\n"
     ]
    }
   ],
   "source": [
    "# Define function and role names\n",
    "LAMBDA_FUNCTION_NAME = f\"execute-modified-dsl-query-{agent_suffix}\"\n",
    "# IAM_ROLE_NAME = f\"LambdaExecutionRole-{agent_suffix}\"\n",
    "ZIP_FILE_NAME = \"function.zip\"\n",
    "LAMBDA_FILE_PATH = \"src/lambda/execute_modified_dsl_query.py\"\n",
    "DEPENDENCIES = [\"opensearch-py\", \"requests\", \"urllib3\"]  # Required packages\n",
    "\n",
    "\n",
    "# Step 1: Create IAM Role for Lambda\n",
    "# role_arn = create_iam_role(IAM_ROLE_NAME)\n",
    "\n",
    "# Step 2: Zip the existing lambda function file\n",
    "if not os.path.exists(LAMBDA_FILE_PATH):\n",
    "    print(f\"Error: {LAMBDA_FILE_PATH} does not exist. Create the file first.\")\n",
    "    exit(1)\n",
    "\n",
    "# Step 3: Package Lambda function and dependencies\n",
    "create_lambda_package(LAMBDA_FILE_PATH, ZIP_FILE_NAME)\n",
    "\n",
    "# Step 4: Create or update the Lambda function\n",
    "response = create_lambda_function(\n",
    "    function_name=LAMBDA_FUNCTION_NAME,\n",
    "    role_arn=role_arn,\n",
    "    handler=\"execute_modified_dsl_query.lambda_handler\",\n",
    "    runtime=\"python3.12\",\n",
    "    zip_file_path=ZIP_FILE_NAME\n",
    ")\n",
    "\n",
    "# Step 4: Add resource-based policy to the Lambda function\n",
    "add_resource_based_policy(LAMBDA_FUNCTION_NAME, [dsl_query_agent_id,query_fixer_agent_id], region, account_id)\n",
    "\n",
    "# add_resource_based_policy(LAMBDA_FUNCTION_NAME, query_fixer_agent_id, region, account_id)\n",
    "\n",
    "\n",
    "# Cleanup: Remove temporary ZIP file\n",
    "os.remove(ZIP_FILE_NAME)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervisor_agent = SupervisorAgent.direct_create(\n",
    "#     name=f\"supervisor-agent-{agent_suffix}\",\n",
    "#     role=\"Supervisor who reviews and approves the generated DSL queries\",\n",
    "#     collaboration_type=\"SUPERVISOR\",  # or \"ORCHESTRATION\"\n",
    "#     collaborator_objects=[dsl_query_agent],\n",
    "#     collaborator_agents=[\n",
    "#         {\n",
    "#             \"agent\": dsl_query_agent.name,\n",
    "#             \"instructions\": \"Use for generating DSL queries\",\n",
    "#             \"relay_conversation_history\": \"DISABLED\"\n",
    "#         }\n",
    "#     ],\n",
    "#     instructions=f\"\"\"\n",
    "#     You are a supervisor responsible for reviewing and approving the generated DSL queries. Your task is to ensure that the generated queries are accurate and follow the provided schema.\n",
    "    \n",
    "#     ## Instructions:\n",
    "#     - Review the generated Query DSL for accuracy and completeness.\n",
    "#     - Ensure that the generated query adheres to the provided e-commerce shipping schema.\n",
    "#     - Approve the query if it meets the requirements.\n",
    "#     - Provide feedback for any necessary changes.\n",
    "#     \"\"\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting existing agent and corresponding lambda for: query-fixer-agent-us-west-2-533...\n",
      "Agent query-fixer-agent-us-west-2-533 not found\n",
      "Creating agent query-fixer-agent-us-west-2-533...\n",
      "Created agent, id: QXAMFSD0AH, alias id: TSTALIASID\n",
      "\n",
      "Adding action group with Lambda: arn:aws:lambda:us-west-2:533267284022:function:execute-modified-dsl-query-us-west-2-533...\n",
      "Waiting for agent status to change. Current status CREATING\n",
      "Agent id QXAMFSD0AH current status: NOT_PREPARED\n",
      "Waiting for agent status to change. Current status VERSIONING\n",
      "Agent id QXAMFSD0AH current status: PREPARED\n",
      "DONE: Agent: query-fixer-agent-us-west-2-533, id: QXAMFSD0AH, alias id: DMAV6XDDGA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the collaborator agent\n",
    "query_fixer_agent = Agent.direct_create(\n",
    "    name=f\"query-fixer-agent-{agent_suffix}\",\n",
    "    role=\"Query Repair Specialist\",\n",
    "    goal=\"Fix and optimize failed DSL queries\",\n",
    "    instructions=f\"\"\"\n",
    "    You are an expert query debugger and optimizer. Your tasks are:\n",
    "    1. Analyze failed DSL queries from the query generator\n",
    "    2. Diagnose errors using OpenSearch error messages\n",
    "    3. Apply targeted fixes while maintaining original intent\n",
    "    4. Optimize queries for better recall when results are empty\n",
    "    \n",
    "    ## Repair Strategies:\n",
    "    - SYNTAX ERRORS: Fix formatting issues in nested queries/aggregations\n",
    "    - FIELD ERRORS: Map invalid fields to valid schema equivalents\n",
    "    - ZERO HITS: Apply query relaxation techniques:\n",
    "      * Add wildcards to keyword searches\n",
    "      * Expand date ranges\n",
    "      * Reduce strictness of term matches\n",
    "      * Add synonym expansion\n",
    "    \n",
    "    ## Optimization Rules:\n",
    "    - Maintain original query structure where possible\n",
    "    - Prefer query-time fixes over rearchitecting\n",
    "    - Document all modifications in revision notes\n",
    "    - Limit query relaxation to 3 iterations\n",
    "    \n",
    "    ## Schema:\n",
    "    {ecom_shipping_schema_string}\n",
    "    \n",
    "    ## Output Format:\n",
    "    - Return modified query in <json> tags\n",
    "    - Include revision notes in <notes> tags\n",
    "    \"\"\",\n",
    "    tool_code=f\"arn:aws:lambda:{region}:{account_id}:function:execute-modified-dsl-query-us-west-2-533\",\n",
    "    tool_defs=[\n",
    "        {\n",
    "            \"name\": \"retry_query\",\n",
    "            \"description\": \"Retries a modified version of the failed query\",\n",
    "            \"parameters\": {\n",
    "                \"modified_dsl_query\": {\n",
    "                    \"description\": \"The corrected DSL query\",\n",
    "                    \"type\": \"string\",\n",
    "                    \"required\": True\n",
    "                },\n",
    "                \"revision_notes\": {\n",
    "                    \"description\": \"Description of modifications made\",\n",
    "                    \"type\": \"string\",\n",
    "                },\n",
    "            }   \n",
    "        }   \n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent supervisor-agent-us-west-2-533 not found\n",
      "\n",
      "Created supervisor, id: IDMVVHEYST, alias id: TSTALIASID\n",
      "\n",
      "  associating sub-agents / collaborators to supervisor...\n",
      "Waiting for agent status to change. Current status CREATING\n",
      "Agent id IDMVVHEYST current status: NOT_PREPARED\n",
      "Waiting for agent status to change. Current status PREPARING\n",
      "Agent id IDMVVHEYST current status: PREPARED\n",
      "Waiting for agent status to change. Current status PREPARING\n",
      "Agent id IDMVVHEYST current status: PREPARED\n",
      "DONE: Agent: supervisor-agent-us-west-2-533, id: IDMVVHEYST, alias id: JWFPYUHMKB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "supervisor_agent = SupervisorAgent.direct_create(\n",
    "    name=f\"supervisor-agent-{agent_suffix}\",\n",
    "    role=\"Query Pipeline Orchestrator\",\n",
    "    collaboration_type=\"SUPERVISOR\",\n",
    "    collaborator_objects=[dsl_query_agent, query_fixer_agent],\n",
    "    collaborator_agents=[\n",
    "        {\n",
    "            \"agent\": dsl_query_agent.name,\n",
    "            \"instructions\": \"Primary DSL query generation using the schema\",\n",
    "            \"relay_conversation_history\": \"DISABLED\"\n",
    "        },\n",
    "        {\n",
    "            \"agent\": query_fixer_agent.name,\n",
    "            \"instructions\": dedent(\"\"\"\n",
    "                Engage when:\n",
    "                1. DSL query returns errors (parsing/validation)\n",
    "                2. Search results are empty (zero hits)\n",
    "                3. Query needs optimization for better recall\n",
    "                \n",
    "                Responsibilities:\n",
    "                - Analyze error messages and query structure\n",
    "                - Apply targeted fixes while preserving intent\n",
    "                - Implement query relaxation strategies\n",
    "                - Document modifications made\n",
    "                \"\"\"),\n",
    "            \"relay_conversation_history\": \"TO_COLLABORATOR\"\n",
    "        }\n",
    "    ],\n",
    "    instructions=dedent(f\"\"\"\n",
    "    Orchestrate the end-to-end query generation and validation workflow:\n",
    "    \n",
    "    1. Initial Query Generation:\n",
    "    - Receive natural language query from user\n",
    "    - Route to DSL Query Agent for initial construction\n",
    "    - Validate query structure against schema:\n",
    "      {ecom_shipping_schema_string}\n",
    "    \n",
    "    2. Error Handling & Retry:\n",
    "    - Monitor for query execution errors\n",
    "    - On error/zero results:\n",
    "      a. Capture error context and original query\n",
    "      b. Route to Query Fixer Agent with full diagnostics\n",
    "      c. Validate fixer's modified query\n",
    "      d. Approve max 3 retry attempts\n",
    "    \n",
    "    3. Quality Assurance:\n",
    "    - Ensure final query meets quality standards:\n",
    "      - Proper use of nested queries\n",
    "      - Correct field types and mappings\n",
    "      - Appropriate query strictness level\n",
    "    - Maintain audit trail of all query versions\n",
    "    - Provide user with cleaned error explanations\n",
    "    \n",
    "    4. Final Approval:\n",
    "    - Sign off on valid queries\n",
    "    - Block invalid queries with detailed feedback\n",
    "    - Generate execution summary with:\n",
    "      - Query versions attempted\n",
    "      - Modification reasons\n",
    "      - Performance metrics\n",
    "    \"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invokeAgent API request ID: 09695c4e-acfd-41c9-a360-7b37a2008467\n",
      "invokeAgent API session ID: 12345\n",
      "  agent id: IDMVVHEYST, agent alias id: JWFPYUHMKB\n",
      "\u001b[32m---- Step 1 ----\u001b[0m\n",
      "\u001b[33mTook 5.3s, using 1965 tokens (in: 1800, out: 165) to complete prior action, observe, orchestrate.\u001b[0m\n",
      "\u001b[34mI need to help generate a DSL query to find orders shipped by DHL carrier. Let me first send this request to the DSL query agent to construct the appropriate query.\u001b[0m\n",
      "\u001b[35mUsing sub-agent collaborator: 'dsl-query-agent-us-west-2-533 [AK3UI7V9RL/BDZDCS2YJE]' passing input text:\u001b[0m\n",
      "\u001b[35mPlease generate a DSL query to count the number of shipping orders where the delivery carrier is DHL. Use the shipping index and the proper field path delivery.carrier.\n",
      "\u001b[0m\n",
      "\u001b[32m---- Step 1.1 [using sub-agent name:dsl-query-agent-us-west-2-533, id:AK3UI7V9RL/BDZDCS2YJE] ----\u001b[0m\n",
      "\u001b[33mTook 9.8s, using 1838 tokens (in: 1468, out: 370) to complete prior action, observe, orchestrate.\u001b[0m\n",
      "\u001b[34mTo create this query, we need to:\n",
      "1. Use the \"shipping\" index as specified.\n",
      "2. Filter for documents where the delivery carrier is DHL.\n",
      "3. Use a term query for exact matching on the keyword field.\n",
      "4. Use a count query to get the total number of matching documents.\n",
      "\n",
      "The field path for the carrier is \"delivery.carrier\" as mentioned in the request.\n",
      "</thinking>\n",
      "\n",
      "Here's the DSL query that will accomplish this:\n",
      "\n",
      "<json>\n",
      "{\n",
      "  \"query\": {\n",
      "    \"term\": {\n",
      "      \"delivery.carrier\": \"DHL\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "</json>\n",
      "\n",
      "<thinking>\n",
      "Now that we have constructed the DSL query, we need to execute it using the provided function to get the count of shipping orders with DHL as the carrier. Let's use the `actions_dsl-query-agent-us-west-2-533__execute_dsl_query` function to do this.\u001b[0m\n",
      "\u001b[35mUsing tool: execute_dsl_query with these inputs:\u001b[0m\n",
      "\u001b[35m[{'name': 'dsl_query', 'type': 'string', 'value': '{\\n  \"query\": {\\n    \"term\": {\\n      \"delivery.carrier\": \"DHL\"\\n    }\\n  }\\n}'}]\n",
      "\u001b[0m\n",
      "\u001b[35m--tool outputs:\n",
      "{'TEXT': {'body': {'took': 22, 'timed_out': False, '_shards': {'total': 0, 'successful': 0, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 0, 'relation': 'eq'}, 'max_score': None, 'hits': []}}}}...\n",
      "\u001b[0m\n",
      "\u001b[32m---- Step 1.2 [using sub-agent name:dsl-query-agent-us-west-2-533, id:AK3UI7V9RL/BDZDCS2YJE] ----\u001b[0m\n",
      "\u001b[33mTook 6.2s, using 2008 tokens (in: 1895, out: 113) to complete prior action, observe, orchestrate.\u001b[0m\n",
      "\u001b[34mThe query has been executed successfully. Let's analyze the results:\n",
      "\n",
      "1. The query took 22 milliseconds to execute.\n",
      "2. It didn't time out.\n",
      "3. The 'hits' section shows that the total value is 0.\n",
      "\n",
      "This means that there are currently no shipping orders in the index where the delivery carrier is DHL.\u001b[0m\n",
      "\u001b[36mFinal response:\n",
      "Based on the query results, there are currently 0 shipping orders where the delivery carrier is DHL....\u001b[0m\n",
      "\u001b[35m\n",
      "----sub-agent dsl-query-agent-us-west-2-533 output text:\n",
      "Based on the query results, there are currently 0 shipping orders where the delivery carrier is DHL....\n",
      "\u001b[0m\n",
      "\u001b[32m---- Step 2 ----\u001b[0m\n",
      "\u001b[33mTook 5.2s, using 2191 tokens (in: 1994, out: 197) to complete prior action, observe, orchestrate.\u001b[0m\n",
      "\u001b[34mSince we got zero results, I should engage the query fixer agent to verify if there might be any issues with the query or if we need to try alternative approaches.\u001b[0m\n",
      "\u001b[35mUsing sub-agent collaborator: 'query-fixer-agent-us-west-2-533 [QXAMFSD0AH/DMAV6XDDGA]' passing input text:\u001b[0m\n",
      "\u001b[35mThe query for counting shipping orders with delivery.carrier = \"DHL\" returned zero results. Can you please verify if:\n",
      "1. The carrier name might be stored in a different format (e.g., lowercase, different abbreviation)\n",
      "2. If we need to adjust the query structure\n",
      "Please suggest any modifications to im\n",
      "\u001b[0m\n",
      "\u001b[32m---- Step 2.1 [using sub-agent name:query-fixer-agent-us-west-2-533, id:QXAMFSD0AH/DMAV6XDDGA] ----\u001b[0m\n",
      "\u001b[33mTook 15.0s, using 2032 tokens (in: 1476, out: 556) to complete prior action, observe, orchestrate.\u001b[0m\n",
      "\u001b[34mTo address this issue, I'll need to analyze the query that returned zero results and suggest modifications to improve the search. I'll focus on verifying the carrier name format and adjusting the query structure if necessary. Let's start by examining and modifying the query.\n",
      "\n",
      "First, I'll create a modified query that addresses the potential issues:\n",
      "1. I'll use a case-insensitive match for the carrier name.\n",
      "2. I'll include variations of the carrier name (e.g., \"dhl\", \"DHL Express\").\n",
      "3. I'll use a more relaxed query structure to ensure we're not missing any results due to strict matching.\u001b[0m\n",
      "Caught exception while processing input to invokeAgent:\n",
      "\n",
      "  for input text:\n",
      "How many orders have been shipped by DHL?\n",
      "\n",
      "  on agent: IDMVVHEYST, alias: JWFPYUHMKB\n",
      "  request ID: 09695c4e-acfd-41c9-a360-7b37a2008467, retries: 0\n",
      "\n",
      "Error: An error occurred (dependencyFailedException) when calling the InvokeAgent operation: Agent query-fixer-agent-us-west-2-533 failed to process the request with error Your request couldn't be completed. Lambda function arn:aws:lambda:us-west-2:533267284022:function:execute-modified-dsl-query-us-west-2-533 encountered a problem while processing request.The error message from the Lambda function is Unhandled. Check the Lambda function log for error details, then try your request again after fixing the error. (Service: bedrock, Status Code: 424, Request ID: 53b73b69-ec37-477e-94d8-a9fee902ee73)\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "('Unexpected exception: ', EventStreamError(\"An error occurred (dependencyFailedException) when calling the InvokeAgent operation: Agent query-fixer-agent-us-west-2-533 failed to process the request with error Your request couldn't be completed. Lambda function arn:aws:lambda:us-west-2:533267284022:function:execute-modified-dsl-query-us-west-2-533 encountered a problem while processing request.The error message from the Lambda function is Unhandled. Check the Lambda function log for error details, then try your request again after fixing the error. (Service: bedrock, Status Code: 424, Request ID: 53b73b69-ec37-477e-94d8-a9fee902ee73)\"))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEventStreamError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/Code/agentic-rag-research/agentic-rag-research/hybrid-rag/src/utils/bedrock_agent_helper.py:1455\u001b[0m, in \u001b[0;36mAgentsForAmazonBedrock.invoke\u001b[0;34m(self, input_text, agent_id, agent_alias_id, session_id, session_state, enable_trace, end_session, trace_level, multi_agent_names)\u001b[0m\n\u001b[1;32m   1454\u001b[0m _sub_agent_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<collab-name-not-yet-provided>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1455\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_event\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_event_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1456\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_sub_agent_alias_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/genai-on-aws/lib/python3.12/site-packages/botocore/eventstream.py:592\u001b[0m, in \u001b[0;36mEventStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_generator:\n\u001b[0;32m--> 592\u001b[0m     parsed_event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parsed_event:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/genai-on-aws/lib/python3.12/site-packages/botocore/eventstream.py:608\u001b[0m, in \u001b[0;36mEventStream._parse_event\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 608\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m EventStreamError(parsed_response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_operation_name)\n",
      "\u001b[0;31mEventStreamError\u001b[0m: An error occurred (dependencyFailedException) when calling the InvokeAgent operation: Agent query-fixer-agent-us-west-2-533 failed to process the request with error Your request couldn't be completed. Lambda function arn:aws:lambda:us-west-2:533267284022:function:execute-modified-dsl-query-us-west-2-533 encountered a problem while processing request.The error message from the Lambda function is Unhandled. Check the Lambda function log for error details, then try your request again after fixing the error. (Service: bedrock, Status Code: 424, Request ID: 53b73b69-ec37-477e-94d8-a9fee902ee73)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43msupervisor_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHow many orders have been shipped by DHL?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43msession_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m12345\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_trace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrace_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Code/agentic-rag-research/agentic-rag-research/hybrid-rag/src/utils/bedrock_agent.py:825\u001b[0m, in \u001b[0;36mSupervisorAgent.invoke\u001b[0;34m(self, input_text, session_id, enable_trace, trace_level, session_state, multi_agent_names)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_agent_names \u001b[38;5;241m==\u001b[39m {}:\n\u001b[1;32m    824\u001b[0m     multi_agent_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_agent_names\n\u001b[0;32m--> 825\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43magents_helper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupervisor_agent_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent_alias_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupervisor_agent_alias_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m    \u001b[49m\u001b[43msession_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_trace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43msession_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrace_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrace_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_agent_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_agent_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Code/agentic-rag-research/agentic-rag-research/hybrid-rag/src/utils/bedrock_agent_helper.py:1915\u001b[0m, in \u001b[0;36mAgentsForAmazonBedrock.invoke\u001b[0;34m(self, input_text, agent_id, agent_alias_id, session_id, session_state, enable_trace, end_session, trace_level, multi_agent_names)\u001b[0m\n\u001b[1;32m   1911\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m   1912\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  request ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_agent_resp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResponseMetadata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRequestId\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, retries: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_agent_resp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResponseMetadata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetryAttempts\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1913\u001b[0m )\n\u001b[1;32m   1914\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1915\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected exception: \u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n",
      "\u001b[0;31mException\u001b[0m: ('Unexpected exception: ', EventStreamError(\"An error occurred (dependencyFailedException) when calling the InvokeAgent operation: Agent query-fixer-agent-us-west-2-533 failed to process the request with error Your request couldn't be completed. Lambda function arn:aws:lambda:us-west-2:533267284022:function:execute-modified-dsl-query-us-west-2-533 encountered a problem while processing request.The error message from the Lambda function is Unhandled. Check the Lambda function log for error details, then try your request again after fixing the error. (Service: bedrock, Status Code: 424, Request ID: 53b73b69-ec37-477e-94d8-a9fee902ee73)\"))"
     ]
    }
   ],
   "source": [
    "response = supervisor_agent.invoke(\n",
    "    input_text=\"How many orders have been shipped by DHL?\",\n",
    "    session_id=\"12345\",\n",
    "    enable_trace=True,\n",
    "    trace_level=\"core\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize the Lambda client\n",
    "# lambda_client = boto3.client('lambda')\n",
    "\n",
    "# # List and delete all agents\n",
    "# def delete_all_agents():\n",
    "#     try:\n",
    "#         agents = agents_helper.list_agents()\n",
    "#         for agent in agents:\n",
    "#             agent_name = agent['name']\n",
    "#             print(f\"Deleting agent: {agent_name}\")\n",
    "#             agents_helper.delete_agent(agent_name, verbose=True)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error deleting agents: {e}\")\n",
    "\n",
    "# # List and delete all Lambda functions\n",
    "# def delete_all_lambdas():\n",
    "#     try:\n",
    "#         functions = lambda_client.list_functions()['Functions']\n",
    "#         for function in functions:\n",
    "#             function_name = function['FunctionName']\n",
    "#             print(f\"Deleting Lambda function: {function_name}\")\n",
    "#             lambda_client.delete_function(FunctionName=function_name)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error deleting Lambda functions: {e}\")\n",
    "\n",
    "# # Execute the deletion\n",
    "# delete_all_agents()\n",
    "# delete_all_lambdas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found target agent, name: supervisor-agent-us-west-2-533, id: VBSJHKQYKV\n",
      "Deleting aliases for agent VBSJHKQYKV...\n",
      "Deleting alias IXSB3ZOKXH from agent VBSJHKQYKV\n",
      "Deleting alias TSTALIASID from agent VBSJHKQYKV\n",
      "Deleting agent: VBSJHKQYKV...\n",
      "Deleting IAM role: AmazonBedrockExecutionRoleForAgents_supervisor-agent-us-west-2-533...\n"
     ]
    }
   ],
   "source": [
    "agents_helper.delete_agent(supervisor_agent.name, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found target agent, name: dsl-query-agent-us-west-2-533, id: SUEHTY8JWX\n",
      "Deleting aliases for agent SUEHTY8JWX...\n",
      "Deleting alias QUG2KO9VUW from agent SUEHTY8JWX\n",
      "Deleting alias TSTALIASID from agent SUEHTY8JWX\n",
      "Deleting agent: SUEHTY8JWX...\n",
      "Deleting IAM role: AmazonBedrockExecutionRoleForAgents_dsl-query-agent-us-west-2-533...\n"
     ]
    }
   ],
   "source": [
    "agents_helper.delete_agent(dsl_query_agent.name, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found target agent, name: query-fixer-agent-us-west-2-533, id: 6B0GY0XBMJ\n",
      "Deleting aliases for agent 6B0GY0XBMJ...\n",
      "Deleting alias TSTALIASID from agent 6B0GY0XBMJ\n",
      "Deleting alias TUMWYE8LDW from agent 6B0GY0XBMJ\n",
      "Deleting agent: 6B0GY0XBMJ...\n",
      "Deleting IAM role: AmazonBedrockExecutionRoleForAgents_query-fixer-agent-us-west-2-533...\n"
     ]
    }
   ],
   "source": [
    "agents_helper.delete_agent(query_fixer_agent.name, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-on-aws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
